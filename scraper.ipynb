{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install requests\n",
    "!pip install  selenium\n",
    "!pip install  webdriver_manager\n",
    "!pip install beautifulsoup4\n",
    "!pip install undetected_chromedriver\n",
    "!pip install selenium_stealth\n",
    "!pip install webdriver-manager\n",
    "!pip install amazoncaptcha\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from amazoncaptcha import AmazonCaptcha\n",
    "\n",
    "import undetected_chromedriver as uc\n",
    "\n",
    "from selenium_stealth import stealth\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.chrome.options import Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "chrome_options = uc.ChromeOptions()\n",
    "\n",
    "# chrome_options.add_argument('--proxy-server=%s' % PROXY)\n",
    "chrome_options.add_experimental_option('useAutomationExtension', False)\n",
    "\n",
    "chrome_options.add_argument(\"--disable-blink-features\")\n",
    "chrome_options.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "# Exclude the collection of enable-automation switches \n",
    "chrome_options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "# chrome_options.add_argument('--disable-gpu')\n",
    "# chrome_options.add_argument('--headless') \n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()),  options=chrome_options)\n",
    "stealth(driver,\n",
    "        languages=[\"en-US\", \"en\"],\n",
    "        vendor=\"Google Inc.\",\n",
    "        platform=\"Win32\",\n",
    "        webgl_vendor=\"Intel Inc.\",\n",
    "        renderer=\"Intel Iris OpenGL Engine\",\n",
    "        fix_hairline=True,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.ebay.com/b/Jordan-1-Retro-OG-High-UNC-Toe/15709/bn_7119139207')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.amazon.com/errors/validateCaptcha')\n",
    "\n",
    "captcha = AmazonCaptcha.fromdriver(driver)\n",
    "solution = captcha.solve(keep_logs=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = driver.page_source\n",
    "soup = BeautifulSoup(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# url = 'https://www.ebay.com/b/Jordan-3-Retro-Mid-White-Cement-Reimagined/15709/bn_7118614226'\n",
    "url = 'https://www.wayfair.com/furniture/pdp/touch-rich-16-small-footstool-pu-leather-ottoman-footrest-modern-home-living-room-bedroom-rectangular-stool-with-padded-seat-brown-quch1039.html?piid=86307424'\n",
    "# url = 'https://www.ebay.com/b/Jordan-1-Retro-OG-High-UNC-Toe/15709/bn_7119139207'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "def get_amazon_reviews(url):\n",
    "    headers = {'User-Agent': \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/42.0.2311.135 Safari/537.36 Edge/12.246\"}\n",
    "\n",
    "    response = requests.get(url, headers=headers)\n",
    "    # add response code\n",
    "    print(response.status_code)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    # print(soup.prettify())\n",
    "\n",
    "    reviews = soup.find_all('div', {'class': 'kzv0b8kg_6101'})\n",
    "    print(reviews)\n",
    "\n",
    "get_amazon_reviews(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "payload = { 'api_key': '4e1141690db55b5b1e2b95ceec4cd5af', 'url': 'https://www.amazon.com/', 'country_code': 'us', 'device_type': 'desktop' } \n",
    "r = requests.get('https://api.scraperapi.com/', params=payload)\n",
    "print(r.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "Amazon.com : Amazon Basics Neoprene Coated Hexagon Workout Dumbbell Hand Weight, 20 Pounds, 10 Pound (Set of 2), Navy Blue : Sports & Outdoors\n",
      "Name: So Wickesited\n",
      "Date: Reviewed in the United States on January 1, 2024\n",
      "Review: These weights provide the best bang for your buck. You might be able to get lucky and find cheaper used weights on classifieds, but for new weights you can't get better. They're durable, accurate weight, and the soft touch makes it easy to hold even if your hands are a little sweaty.I do feel bad watching the delivery guy struggle with a couple boxes, though, when he didn't realize this box had weights inside.\n",
      "------------------------\n",
      "Name: givz\n",
      "Date: Reviewed in the United States on December 14, 2023\n",
      "Review: I like them very much. The weights are easy to hold and do not irritate my hands' skin. The price is excellent, so these weights have been incredible for home workouts.\n",
      "------------------------\n",
      "Name: Bruce Liu\n",
      "Date: Reviewed in the United States on January 6, 2024\n",
      "Review: Well, good product as described. Good grips.\n",
      "------------------------\n",
      "Name: Amanda H.\n",
      "Date: Reviewed in the United States on December 12, 2023\n",
      "Review: They‚Äôre nice weights. The neoprene is great for me because I find the metal ones slippery if my hands sweat. They‚Äôre easy to hold and seem durable. I gave 4 stars just because I‚Äôm not a fan of the color, however the color is true to the advertised photo.\n",
      "------------------------\n",
      "Name: scarcio\n",
      "Date: Reviewed in the United States on December 23, 2023\n",
      "Review: Rubber coated for in home use, they are color coated so at first glance, you know what to grab. Amazon Prime make it an extra value with free shipping! I highly recommend these.\n",
      "------------------------\n",
      "Name: Rose\n",
      "Date: Reviewed in the United States on January 9, 2024\n",
      "Review: Purchase these for work while I was on break at work, very light. Beautiful color. Easy to use, the right weight. Really great for fast weight lifting during lunch hour.\n",
      "------------------------\n",
      "Name: George Lopez\n",
      "Date: Reviewed in the United States on December 17, 2023\n",
      "Review: I just got these today. I know everybody skeptical cause some of the bad reviews on these, but the box that I got was not damaged every weight had its own individual box inside the box it was wrapped in a clear plastic cover, all clean all new you have to assemble the stand which takes 5 screws each side for a total of 10 screws. The only probably cheap thing you could say is the stands made out of plastic, but not cheap plastic. It‚Äôs firm once you put it together the total weights weight 32 pounds combined might be a little heavy for some people but like I said, it‚Äôs packed very well very pleased. All weights are balanced as close to true. It‚Äôs unfortunate p, some of the people that had some bad experiences with this. I feel bad for them but mine is brand new never been used. No marks all clean as you can. Look at the pictures that I sent. Good luck get strong be safe. üëç\n",
      "------------------------\n",
      "Name: GREGORY SHELTON SR.\n",
      "Date: Reviewed in the United States on January 9, 2024\n",
      "Review: I was looking for a covered pair of twenty pound weights for my collection. For some reason choices of covered weights above 15 pounds were not easy to find. I was happy to get them on time and in good condition. They fit on my existing dumbbell rack and felt good. The only small concern is the grip section takes a large hand to hold the weight, I guess because of the cushion wrap and the 20lb size. Alright for my big hands but a smaller grip might have a problem, say for instance my wife.\n",
      "------------------------\n",
      "Name: Mar√≠a Paula \n",
      "Date: Reviewed in Mexico on January 5, 2024\n",
      "Review: Excelente peso y tama√±o para hacer ejercicio\n",
      "------------------------\n",
      "Name: Freesia\n",
      "Date: Reviewed in Canada on December 30, 2023\n",
      "Review: Got these as 'pre-owned from Amazondeals but they look brand new to me! I have them all from 2lbs onward and the 15lbs are my kinda graduation to a good result in my training, considering I am still in recovery from an injury. Love these, great price and does the job well, equal weight and good grip, long lasting.\n",
      "------------------------\n",
      "Name: M\n",
      "Date: Reviewed in Mexico on November 28, 2023\n",
      "Review: Buen tama√±o y calidad\n",
      "------------------------\n",
      "Name: Rod\n",
      "Date: Reviewed in Canada on November 21, 2023\n",
      "Review: These Neoprene Workout Dumbbell are great.  Easy to hold and use.  Purchased these to  build up a little muscle and keep flexibility going to the body.  Our family use these daily .  Great product  great price.\n",
      "------------------------\n",
      "Name: red\n",
      "Date: Reviewed in Mexico on November 14, 2023\n",
      "Review: Resistentes,  ahorra espacios, adaptables\n",
      "------------------------\n"
     ]
    }
   ],
   "source": [
    "# amazon  review scraping\n",
    "\n",
    "def get_amazon_reviews():\n",
    "    payload = { 'api_key': '4e1141690db55b5b1e2b95ceec4cd5af', 'url': 'https://www.amazon.com/AmazonBasics-Pound-Neoprene-Dumbbells-Weights/dp/B01LR5S6HK/?_encoding=UTF8&pd_rd_w=jX876&content-id=amzn1.sym.64be5821-f651-4b0b-8dd3-4f9b884f10e5&pf_rd_p=64be5821-f651-4b0b-8dd3-4f9b884f10e5&pf_rd_r=WQ1CA8YTG0VXZPBAXPPD&pd_rd_wg=jz7z3&pd_rd_r=bbc1b88d-65eb-4bf5-93ba-25759a3674a4&ref_=pd_gw_crs_zg_bs_3375251&th=1', 'country_code': 'us', 'device_type': 'desktop' }\n",
    "\n",
    "    response = requests.get('https://api.scraperapi.com/', params=payload)\n",
    "    # add response code\n",
    "    print(response.status_code)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    # print(soup.prettify())\n",
    "    # find title tag\n",
    "    title = soup.find('title').text\n",
    "    print(title)\n",
    "    reviews = soup.find_all('div', {'data-hook': 'review'})\n",
    "    \n",
    "\n",
    "    # print(reviews)\n",
    "    for review in reviews:\n",
    "        name = review.find('span', {'class': 'a-profile-name'}).text\n",
    "        date = review.find('span', {'data-hook': 'review-date'}).text\n",
    "\n",
    "        # Extracting the review body, handling collapsed content\n",
    "        review_body_span = review.find('span', {'data-hook': 'review-body'})\n",
    "        review_body = review_body_span.find('span').text if review_body_span else \"\"\n",
    "\n",
    "        print(f\"Name: {name}\")\n",
    "        print(f\"Date: {date}\")\n",
    "        print(f\"Review: {review_body}\")\n",
    "        print(\"------------------------\")\n",
    "\n",
    "get_amazon_reviews()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.36.2-py3-none-any.whl.metadata (126 kB)\n",
      "     ---------------------------------------- 0.0/126.8 kB ? eta -:--:--\n",
      "     -------- ---------------------------- 30.7/126.8 kB 660.6 kB/s eta 0:00:01\n",
      "     -------- ---------------------------- 30.7/126.8 kB 660.6 kB/s eta 0:00:01\n",
      "     -------------------------- ---------- 92.2/126.8 kB 585.1 kB/s eta 0:00:01\n",
      "     -------------------------- ---------- 92.2/126.8 kB 585.1 kB/s eta 0:00:01\n",
      "     ------------------------------- ---- 112.6/126.8 kB 409.6 kB/s eta 0:00:01\n",
      "     ------------------------------- ---- 112.6/126.8 kB 409.6 kB/s eta 0:00:01\n",
      "     ------------------------------- ---- 112.6/126.8 kB 409.6 kB/s eta 0:00:01\n",
      "     ------------------------------- ---- 112.6/126.8 kB 409.6 kB/s eta 0:00:01\n",
      "     ------------------------------- ---- 112.6/126.8 kB 409.6 kB/s eta 0:00:01\n",
      "     ------------------------------- ---- 112.6/126.8 kB 409.6 kB/s eta 0:00:01\n",
      "     ------------------------------------ 126.8/126.8 kB 219.4 kB/s eta 0:00:00\n",
      "Collecting filelock (from transformers)\n",
      "  Using cached filelock-3.13.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting huggingface-hub<1.0,>=0.19.3 (from transformers)\n",
      "  Using cached huggingface_hub-0.20.2-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting numpy>=1.17 (from transformers)\n",
      "  Using cached numpy-1.26.3-cp39-cp39-win_amd64.whl.metadata (61 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in e:\\zain\\env\\lib\\site-packages (from transformers) (23.2)\n",
      "Collecting pyyaml>=5.1 (from transformers)\n",
      "  Using cached PyYAML-6.0.1-cp39-cp39-win_amd64.whl.metadata (2.1 kB)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Using cached regex-2023.12.25-cp39-cp39-win_amd64.whl.metadata (41 kB)\n",
      "Requirement already satisfied: requests in e:\\zain\\env\\lib\\site-packages (from transformers) (2.30.0)\n",
      "Collecting tokenizers<0.19,>=0.14 (from transformers)\n",
      "  Using cached tokenizers-0.15.0-cp39-none-win_amd64.whl.metadata (6.8 kB)\n",
      "Collecting safetensors>=0.3.1 (from transformers)\n",
      "  Downloading safetensors-0.4.1-cp39-none-win_amd64.whl.metadata (3.8 kB)\n",
      "Collecting tqdm>=4.27 (from transformers)\n",
      "  Using cached tqdm-4.66.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub<1.0,>=0.19.3->transformers)\n",
      "  Using cached fsspec-2023.12.2-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in e:\\zain\\env\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.9.0)\n",
      "Requirement already satisfied: colorama in e:\\zain\\env\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in e:\\zain\\env\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in e:\\zain\\env\\lib\\site-packages (from requests->transformers) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in e:\\zain\\env\\lib\\site-packages (from requests->transformers) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in e:\\zain\\env\\lib\\site-packages (from requests->transformers) (2023.11.17)\n",
      "Downloading transformers-4.36.2-py3-none-any.whl (8.2 MB)\n",
      "   ---------------------------------------- 0.0/8.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.1/8.2 MB 2.6 MB/s eta 0:00:04\n",
      "    --------------------------------------- 0.1/8.2 MB 1.6 MB/s eta 0:00:05\n",
      "    --------------------------------------- 0.2/8.2 MB 1.6 MB/s eta 0:00:06\n",
      "   - -------------------------------------- 0.2/8.2 MB 1.5 MB/s eta 0:00:06\n",
      "   - -------------------------------------- 0.4/8.2 MB 1.5 MB/s eta 0:00:06\n",
      "   -- ------------------------------------- 0.5/8.2 MB 1.7 MB/s eta 0:00:05\n",
      "   -- ------------------------------------- 0.6/8.2 MB 1.6 MB/s eta 0:00:05\n",
      "   --- ------------------------------------ 0.7/8.2 MB 1.8 MB/s eta 0:00:05\n",
      "   ---- ----------------------------------- 0.8/8.2 MB 1.9 MB/s eta 0:00:04\n",
      "   ------ --------------------------------- 1.3/8.2 MB 2.5 MB/s eta 0:00:03\n",
      "   -------- ------------------------------- 1.8/8.2 MB 3.1 MB/s eta 0:00:03\n",
      "   ---------- ----------------------------- 2.2/8.2 MB 3.5 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 2.5/8.2 MB 3.6 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 2.6/8.2 MB 3.7 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 2.9/8.2 MB 3.7 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 3.2/8.2 MB 3.9 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 3.2/8.2 MB 3.9 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 3.2/8.2 MB 3.9 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 3.2/8.2 MB 3.9 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 3.2/8.2 MB 3.9 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 3.2/8.2 MB 3.9 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 3.2/8.2 MB 3.9 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 3.2/8.2 MB 3.9 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 3.2/8.2 MB 3.9 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 3.7/8.2 MB 3.0 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 5.3/8.2 MB 4.0 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 5.4/8.2 MB 4.0 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 5.4/8.2 MB 4.0 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 5.4/8.2 MB 4.0 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 5.4/8.2 MB 4.0 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 5.4/8.2 MB 4.0 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 5.4/8.2 MB 4.0 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 6.2/8.2 MB 3.7 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 6.4/8.2 MB 3.7 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 6.5/8.2 MB 3.7 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 6.7/8.2 MB 3.7 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 6.8/8.2 MB 3.6 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 6.9/8.2 MB 3.6 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 6.9/8.2 MB 3.6 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 6.9/8.2 MB 3.6 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 7.1/8.2 MB 3.5 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 7.1/8.2 MB 3.5 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 7.1/8.2 MB 3.5 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 7.2/8.2 MB 3.3 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 7.5/8.2 MB 3.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  8.2/8.2 MB 3.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  8.2/8.2 MB 3.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  8.2/8.2 MB 3.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  8.2/8.2 MB 3.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 8.2/8.2 MB 3.3 MB/s eta 0:00:00\n",
      "Using cached huggingface_hub-0.20.2-py3-none-any.whl (330 kB)\n",
      "Using cached numpy-1.26.3-cp39-cp39-win_amd64.whl (15.8 MB)\n",
      "Using cached PyYAML-6.0.1-cp39-cp39-win_amd64.whl (152 kB)\n",
      "Using cached regex-2023.12.25-cp39-cp39-win_amd64.whl (269 kB)\n",
      "Downloading safetensors-0.4.1-cp39-none-win_amd64.whl (277 kB)\n",
      "   ---------------------------------------- 0.0/277.8 kB ? eta -:--:--\n",
      "   ----------------------- ---------------- 163.8/277.8 kB 5.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 277.8/277.8 kB 3.4 MB/s eta 0:00:00\n",
      "Using cached tokenizers-0.15.0-cp39-none-win_amd64.whl (2.2 MB)\n",
      "Using cached tqdm-4.66.1-py3-none-any.whl (78 kB)\n",
      "Using cached filelock-3.13.1-py3-none-any.whl (11 kB)\n",
      "Using cached fsspec-2023.12.2-py3-none-any.whl (168 kB)\n",
      "Installing collected packages: tqdm, safetensors, regex, pyyaml, numpy, fsspec, filelock, huggingface-hub, tokenizers, transformers\n",
      "Successfully installed filelock-3.13.1 fsspec-2023.12.2 huggingface-hub-0.20.2 numpy-1.26.3 pyyaml-6.0.1 regex-2023.12.25 safetensors-0.4.1 tokenizers-0.15.0 tqdm-4.66.1 transformers-4.36.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\zain\\env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From e:\\zain\\env\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amazon.com : Amazon Basics Neoprene Coated Hexagon Workout Dumbbell Hand Weight, 20 Pounds, 10 Pound (Set of 2), Navy Blue : Sports & Outdoors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model.safetensors: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 268M/268M [01:57<00:00, 2.27MB/s] \n",
      "tokenizer_config.json: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 48.0/48.0 [00:00<?, ?B/s]\n",
      "vocab.txt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 232k/232k [00:00<00:00, 526kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: So Wickesited\n",
      "Date: Reviewed in the United States on January 1, 2024\n",
      "Review: These weights provide the best bang for your buck. You might be able to get lucky and find cheaper used weights on classifieds, but for new weights you can't get better. They're durable, accurate weight, and the soft touch makes it easy to hold even if your hands are a little sweaty.I do feel bad watching the delivery guy struggle with a couple boxes, though, when he didn't realize this box had weights inside.\n",
      "Sentiment: POSITIVE (confidence: 0.9911)\n",
      "------------------------\n",
      "Name: givz\n",
      "Date: Reviewed in the United States on December 14, 2023\n",
      "Review: I like them very much. The weights are easy to hold and do not irritate my hands' skin. The price is excellent, so these weights have been incredible for home workouts.\n",
      "Sentiment: POSITIVE (confidence: 0.9998)\n",
      "------------------------\n",
      "Name: Bruce Liu\n",
      "Date: Reviewed in the United States on January 6, 2024\n",
      "Review: Well, good product as described. Good grips.\n",
      "Sentiment: POSITIVE (confidence: 0.9998)\n",
      "------------------------\n",
      "Name: Amanda H.\n",
      "Date: Reviewed in the United States on December 12, 2023\n",
      "Review: They‚Äôre nice weights. The neoprene is great for me because I find the metal ones slippery if my hands sweat. They‚Äôre easy to hold and seem durable. I gave 4 stars just because I‚Äôm not a fan of the color, however the color is true to the advertised photo.\n",
      "Sentiment: POSITIVE (confidence: 0.9993)\n",
      "------------------------\n",
      "Name: scarcio\n",
      "Date: Reviewed in the United States on December 23, 2023\n",
      "Review: Rubber coated for in home use, they are color coated so at first glance, you know what to grab. Amazon Prime make it an extra value with free shipping! I highly recommend these.\n",
      "Sentiment: POSITIVE (confidence: 0.9986)\n",
      "------------------------\n",
      "Name: Rose\n",
      "Date: Reviewed in the United States on January 9, 2024\n",
      "Review: Purchase these for work while I was on break at work, very light. Beautiful color. Easy to use, the right weight. Really great for fast weight lifting during lunch hour.\n",
      "Sentiment: POSITIVE (confidence: 0.9998)\n",
      "------------------------\n",
      "Name: George Lopez\n",
      "Date: Reviewed in the United States on December 17, 2023\n",
      "Review: I just got these today. I know everybody skeptical cause some of the bad reviews on these, but the box that I got was not damaged every weight had its own individual box inside the box it was wrapped in a clear plastic cover, all clean all new you have to assemble the stand which takes 5 screws each side for a total of 10 screws. The only probably cheap thing you could say is the stands made out of plastic, but not cheap plastic. It‚Äôs firm once you put it together the total weights weight 32 pounds combined might be a little heavy for some people but like I said, it‚Äôs packed very well very pleased. All weights are balanced as close to true. It‚Äôs unfortunate p, some of the people that had some bad experiences with this. I feel bad for them but mine is brand new never been used. No marks all clean as you can. Look at the pictures that I sent. Good luck get strong be safe. üëç\n",
      "Sentiment: POSITIVE (confidence: 0.9877)\n",
      "------------------------\n",
      "Name: GREGORY SHELTON SR.\n",
      "Date: Reviewed in the United States on January 9, 2024\n",
      "Review: I was looking for a covered pair of twenty pound weights for my collection. For some reason choices of covered weights above 15 pounds were not easy to find. I was happy to get them on time and in good condition. They fit on my existing dumbbell rack and felt good. The only small concern is the grip section takes a large hand to hold the weight, I guess because of the cushion wrap and the 20lb size. Alright for my big hands but a smaller grip might have a problem, say for instance my wife.\n",
      "Sentiment: POSITIVE (confidence: 0.9630)\n",
      "------------------------\n",
      "Name: Mar√≠a Paula \n",
      "Date: Reviewed in Mexico on January 5, 2024\n",
      "Review: Excelente peso y tama√±o para hacer ejercicio\n",
      "Sentiment: POSITIVE (confidence: 0.9827)\n",
      "------------------------\n",
      "Name: Freesia\n",
      "Date: Reviewed in Canada on December 30, 2023\n",
      "Review: Got these as 'pre-owned from Amazondeals but they look brand new to me! I have them all from 2lbs onward and the 15lbs are my kinda graduation to a good result in my training, considering I am still in recovery from an injury. Love these, great price and does the job well, equal weight and good grip, long lasting.\n",
      "Sentiment: POSITIVE (confidence: 0.9998)\n",
      "------------------------\n",
      "Name: M\n",
      "Date: Reviewed in Mexico on November 28, 2023\n",
      "Review: Buen tama√±o y calidad\n",
      "Sentiment: POSITIVE (confidence: 0.9739)\n",
      "------------------------\n",
      "Name: Rod\n",
      "Date: Reviewed in Canada on November 21, 2023\n",
      "Review: These Neoprene Workout Dumbbell are great.  Easy to hold and use.  Purchased these to  build up a little muscle and keep flexibility going to the body.  Our family use these daily .  Great product  great price.\n",
      "Sentiment: POSITIVE (confidence: 0.9997)\n",
      "------------------------\n",
      "Name: red\n",
      "Date: Reviewed in Mexico on November 14, 2023\n",
      "Review: Resistentes,  ahorra espacios, adaptables\n",
      "Sentiment: POSITIVE (confidence: 0.9975)\n",
      "------------------------\n",
      "\n",
      "Sentiment Analysis Report:\n",
      "Total Reviews: 13\n",
      "Positive Reviews: 13\n",
      "Neutral Reviews: 0\n",
      "Negative Reviews: 0\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from transformers import pipeline\n",
    "\n",
    "# Amazon review scraping\n",
    "\n",
    "def get_amazon_reviews():\n",
    "    payload = {\n",
    "        'api_key': '4e1141690db55b5b1e2b95ceec4cd5af',\n",
    "        'url': 'https://www.amazon.com/AmazonBasics-Pound-Neoprene-Dumbbells-Weights/dp/B01LR5S6HK/?_encoding=UTF8&pd_rd_w=jX876&content-id=amzn1.sym.64be5821-f651-4b0b-8dd3-4f9b884f10e5&pf_rd_p=64be5821-f651-4b0b-8dd3-4f9b884f10e5&pf_rd_r=WQ1CA8YTG0VXZPBAXPPD&pd_rd_wg=jz7z3&pd_rd_r=bbc1b88d-65eb-4bf5-93ba-25759a3674a4&ref_=pd_gw_crs_zg_bs_3375251&th=1',\n",
    "        'country_code': 'us',\n",
    "        'device_type': 'desktop'\n",
    "    }\n",
    "\n",
    "    response = requests.get('https://api.scraperapi.com/', params=payload)\n",
    "    print(response.status_code)\n",
    "\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    title = soup.find('title').text\n",
    "    print(title)\n",
    "\n",
    "    reviews = soup.find_all('div', {'data-hook': 'review'})\n",
    "\n",
    "    sentiment_analysis_pipeline = pipeline(\"sentiment-analysis\")\n",
    "\n",
    "    positive_reviews = 0\n",
    "    neutral_reviews = 0\n",
    "    negative_reviews = 0\n",
    "\n",
    "    for review in reviews:\n",
    "        name = review.find('span', {'class': 'a-profile-name'}).text\n",
    "        date = review.find('span', {'data-hook': 'review-date'}).text\n",
    "        review_body_span = review.find('span', {'data-hook': 'review-body'})\n",
    "        review_body = review_body_span.find('span').text if review_body_span else \"\"\n",
    "\n",
    "        print(f\"Name: {name}\")\n",
    "        print(f\"Date: {date}\")\n",
    "        print(f\"Review: {review_body}\")\n",
    "\n",
    "        # Perform sentiment analysis\n",
    "        sentiment = sentiment_analysis_pipeline(review_body)\n",
    "        print(f\"Sentiment: {sentiment[0]['label']} (confidence: {sentiment[0]['score']:.4f})\")\n",
    "\n",
    "        if sentiment[0]['label'] == 'POSITIVE':\n",
    "            positive_reviews += 1\n",
    "        elif sentiment[0]['label'] == 'NEUTRAL':\n",
    "            neutral_reviews += 1\n",
    "        elif sentiment[0]['label'] == 'NEGATIVE':\n",
    "            negative_reviews += 1\n",
    "\n",
    "        print(\"------------------------\")\n",
    "\n",
    "    # Generate a report\n",
    "    total_reviews = len(reviews)\n",
    "    print(\"\\nSentiment Analysis Report:\")\n",
    "    print(f\"Total Reviews: {total_reviews}\")\n",
    "    print(f\"Positive Reviews: {positive_reviews}\")\n",
    "    print(f\"Neutral Reviews: {neutral_reviews}\")\n",
    "    print(f\"Negative Reviews: {negative_reviews}\")\n",
    "\n",
    "get_amazon_reviews()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow\n",
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "Amazon.com : Amazon Basics Neoprene Coated Hexagon Workout Dumbbell Hand Weight, 20 Pounds, 10 Pound (Set of 2), Navy Blue : Sports & Outdoors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model.safetensors: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 328M/328M [05:03<00:00, 1.08MB/s] \n",
      "tokenizer_config.json: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1.31k/1.31k [00:00<00:00, 71.8kB/s]\n",
      "vocab.json: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 999k/999k [00:00<00:00, 1.85MB/s]\n",
      "merges.txt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 456k/456k [00:00<00:00, 479kB/s]\n",
      "special_tokens_map.json: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 280/280 [00:00<?, ?B/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: So Wickesited\n",
      "Date: Reviewed in the United States on January 1, 2024\n",
      "Review: These weights provide the best bang for your buck. You might be able to get lucky and find cheaper used weights on classifieds, but for new weights you can't get better. They're durable, accurate weight, and the soft touch makes it easy to hold even if your hands are a little sweaty.I do feel bad watching the delivery guy struggle with a couple boxes, though, when he didn't realize this box had weights inside.\n",
      "Sentiment: negative (confidence: 0.9988)\n",
      "------------------------\n",
      "Name: givz\n",
      "Date: Reviewed in the United States on December 14, 2023\n",
      "Review: I like them very much. The weights are easy to hold and do not irritate my hands' skin. The price is excellent, so these weights have been incredible for home workouts.\n",
      "Sentiment: negative (confidence: 0.9584)\n",
      "------------------------\n",
      "Name: Bruce Liu\n",
      "Date: Reviewed in the United States on January 6, 2024\n",
      "Review: Well, good product as described. Good grips.\n",
      "Sentiment: negative (confidence: 0.5878)\n",
      "------------------------\n",
      "Name: Amanda H.\n",
      "Date: Reviewed in the United States on December 12, 2023\n",
      "Review: They‚Äôre nice weights. The neoprene is great for me because I find the metal ones slippery if my hands sweat. They‚Äôre easy to hold and seem durable. I gave 4 stars just because I‚Äôm not a fan of the color, however the color is true to the advertised photo.\n",
      "Sentiment: negative (confidence: 0.9920)\n",
      "------------------------\n",
      "Name: scarcio\n",
      "Date: Reviewed in the United States on December 23, 2023\n",
      "Review: Rubber coated for in home use, they are color coated so at first glance, you know what to grab. Amazon Prime make it an extra value with free shipping! I highly recommend these.\n",
      "Sentiment: negative (confidence: 0.9969)\n",
      "------------------------\n",
      "Name: Rose\n",
      "Date: Reviewed in the United States on January 9, 2024\n",
      "Review: Purchase these for work while I was on break at work, very light. Beautiful color. Easy to use, the right weight. Really great for fast weight lifting during lunch hour.\n",
      "Sentiment: negative (confidence: 0.9968)\n",
      "------------------------\n",
      "Name: George Lopez\n",
      "Date: Reviewed in the United States on December 17, 2023\n",
      "Review: I just got these today. I know everybody skeptical cause some of the bad reviews on these, but the box that I got was not damaged every weight had its own individual box inside the box it was wrapped in a clear plastic cover, all clean all new you have to assemble the stand which takes 5 screws each side for a total of 10 screws. The only probably cheap thing you could say is the stands made out of plastic, but not cheap plastic. It‚Äôs firm once you put it together the total weights weight 32 pounds combined might be a little heavy for some people but like I said, it‚Äôs packed very well very pleased. All weights are balanced as close to true. It‚Äôs unfortunate p, some of the people that had some bad experiences with this. I feel bad for them but mine is brand new never been used. No marks all clean as you can. Look at the pictures that I sent. Good luck get strong be safe. üëç\n",
      "Sentiment: negative (confidence: 0.9773)\n",
      "------------------------\n",
      "Name: GREGORY SHELTON SR.\n",
      "Date: Reviewed in the United States on January 9, 2024\n",
      "Review: I was looking for a covered pair of twenty pound weights for my collection. For some reason choices of covered weights above 15 pounds were not easy to find. I was happy to get them on time and in good condition. They fit on my existing dumbbell rack and felt good. The only small concern is the grip section takes a large hand to hold the weight, I guess because of the cushion wrap and the 20lb size. Alright for my big hands but a smaller grip might have a problem, say for instance my wife.\n",
      "Sentiment: negative (confidence: 0.9981)\n",
      "------------------------\n",
      "Name: Mar√≠a Paula \n",
      "Date: Reviewed in Mexico on January 5, 2024\n",
      "Review: Excelente peso y tama√±o para hacer ejercicio\n",
      "Sentiment: negative (confidence: 0.9920)\n",
      "------------------------\n",
      "Name: Freesia\n",
      "Date: Reviewed in Canada on December 30, 2023\n",
      "Review: Got these as 'pre-owned from Amazondeals but they look brand new to me! I have them all from 2lbs onward and the 15lbs are my kinda graduation to a good result in my training, considering I am still in recovery from an injury. Love these, great price and does the job well, equal weight and good grip, long lasting.\n",
      "Sentiment: negative (confidence: 0.9666)\n",
      "------------------------\n",
      "Name: M\n",
      "Date: Reviewed in Mexico on November 28, 2023\n",
      "Review: Buen tama√±o y calidad\n",
      "Sentiment: negative (confidence: 0.6665)\n",
      "------------------------\n",
      "Name: Rod\n",
      "Date: Reviewed in Canada on November 21, 2023\n",
      "Review: These Neoprene Workout Dumbbell are great.  Easy to hold and use.  Purchased these to  build up a little muscle and keep flexibility going to the body.  Our family use these daily .  Great product  great price.\n",
      "Sentiment: negative (confidence: 0.9824)\n",
      "------------------------\n",
      "Name: red\n",
      "Date: Reviewed in Mexico on November 14, 2023\n",
      "Review: Resistentes,  ahorra espacios, adaptables\n",
      "Sentiment: negative (confidence: 0.9853)\n",
      "------------------------\n",
      "\n",
      "Sentiment Analysis Report:\n",
      "Total Reviews: 13\n",
      "Positive Reviews: 0\n",
      "Neutral Reviews: 0\n",
      "Negative Reviews: 0\n",
      "\n",
      "Suggestions:\n",
      "The product has a mix of positive and negative reviews. Consider analyzing specific feedback for improvements.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from transformers import pipeline\n",
    "\n",
    "# Amazon review scraping\n",
    "\n",
    "def get_amazon_reviews():\n",
    "    payload = {\n",
    "        'api_key': '4e1141690db55b5b1e2b95ceec4cd5af',\n",
    "        'url': 'https://www.amazon.com/AmazonBasics-Pound-Neoprene-Dumbbells-Weights/dp/B01LR5S6HK/?_encoding=UTF8&pd_rd_w=jX876&content-id=amzn1.sym.64be5821-f651-4b0b-8dd3-4f9b884f10e5&pf_rd_p=64be5821-f651-4b0b-8dd3-4f9b884f10e5&pf_rd_r=WQ1CA8YTG0VXZPBAXPPD&pd_rd_wg=jz7z3&pd_rd_r=bbc1b88d-65eb-4bf5-93ba-25759a3674a4&ref_=pd_gw_crs_zg_bs_3375251&th=1',\n",
    "        'country_code': 'us',\n",
    "        'device_type': 'desktop'\n",
    "    }\n",
    "\n",
    "    response = requests.get('https://api.scraperapi.com/', params=payload)\n",
    "    print(response.status_code)\n",
    "\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    title = soup.find('title').text\n",
    "    print(title)\n",
    "\n",
    "    reviews = soup.find_all('div', {'data-hook': 'review'})\n",
    "\n",
    "    sentiment_analysis_pipeline = pipeline(\"sentiment-analysis\", model=\"mrfakename/distilroberta-financial-news-tweets-sentiment-analysis\")\n",
    "\n",
    "    positive_reviews = 0\n",
    "    neutral_reviews = 0\n",
    "    negative_reviews = 0\n",
    "\n",
    "    for review in reviews:\n",
    "        name = review.find('span', {'class': 'a-profile-name'}).text\n",
    "        date = review.find('span', {'data-hook': 'review-date'}).text\n",
    "        review_body_span = review.find('span', {'data-hook': 'review-body'})\n",
    "        review_body = review_body_span.find('span').text if review_body_span else \"\"\n",
    "\n",
    "        print(f\"Name: {name}\")\n",
    "        print(f\"Date: {date}\")\n",
    "        print(f\"Review: {review_body}\")\n",
    "\n",
    "        # Perform sentiment analysis\n",
    "        sentiment = sentiment_analysis_pipeline(review_body)\n",
    "        print(f\"Sentiment: {sentiment[0]['label']} (confidence: {sentiment[0]['score']:.4f})\")\n",
    "\n",
    "        if sentiment[0]['label'] == 'POSITIVE':\n",
    "            positive_reviews += 1\n",
    "        elif sentiment[0]['label'] == 'NEUTRAL':\n",
    "            neutral_reviews += 1\n",
    "        elif sentiment[0]['label'] == 'NEGATIVE':\n",
    "            negative_reviews += 1\n",
    "\n",
    "        print(\"------------------------\")\n",
    "\n",
    "    # Generate a report with suggestions\n",
    "    total_reviews = len(reviews)\n",
    "    print(\"\\nSentiment Analysis Report:\")\n",
    "    print(f\"Total Reviews: {total_reviews}\")\n",
    "    print(f\"Positive Reviews: {positive_reviews}\")\n",
    "    print(f\"Neutral Reviews: {neutral_reviews}\")\n",
    "    print(f\"Negative Reviews: {negative_reviews}\")\n",
    "\n",
    "    # Provide suggestions based on sentiment analysis\n",
    "    print(\"\\nSuggestions:\")\n",
    "    if positive_reviews > total_reviews * 0.7:\n",
    "        print(\"Customers are generally satisfied with the product. Consider highlighting positive aspects in marketing.\")\n",
    "    elif negative_reviews > total_reviews * 0.5:\n",
    "        print(\"There are concerns raised by customers. Consider addressing these issues to improve satisfaction.\")\n",
    "    else:\n",
    "        print(\"The product has a mix of positive and negative reviews. Consider analyzing specific feedback for improvements.\")\n",
    "\n",
    "get_amazon_reviews()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_amazon_reviews(url):\n",
    "    headers = {'User-Agent': \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/42.0.2311.135 Safari/537.36 Edge/12.246\"}\n",
    "\n",
    "    response = requests.get(url, headers=headers)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    # also  get the product title get it by  title tag\n",
    "\n",
    "    product_title = soup.find('h1', {'class': 'bhp__title'})\n",
    "    print(product_title.text)\n",
    "    \n",
    "    average_rating = soup.find('p', class_='brwrr__rating--title').text.strip()\n",
    "\n",
    "    # Extracting total number of ratings\n",
    "    total_ratings = soup.find('p', class_='brwrr__rating--subtitle').text.strip()\n",
    "\n",
    "    # Extracting individual reviews\n",
    "    reviews = []\n",
    "    review_items = soup.find_all('li', class_='brwel__item')\n",
    "    for item in review_items:\n",
    "        author = item.find('span', class_='brwrr__review__info__author').text.strip()\n",
    "        date = item.find('span', class_='brwrr__review__info__date').text.strip()\n",
    "        title = item.find('p', class_='brwrr__review__title').text.strip()\n",
    "        body = item.find('p', class_='brwrr__review__body').text.strip()\n",
    "        purchase_info = item.find_all('span', class_='textual-display')\n",
    "        verified_purchase = purchase_info[1].text.strip() if len(purchase_info) > 1 else None\n",
    "\n",
    "        review = {\n",
    "            'author': author,\n",
    "            'date': date,\n",
    "            'title': title,\n",
    "            'body': body,\n",
    "            'verified_purchase': verified_purchase\n",
    "        }\n",
    "        reviews.append(review)\n",
    "\n",
    "    # Print the extracted data\n",
    "    print(f'Average Rating: {average_rating}')\n",
    "    print(f'Total Ratings: {total_ratings}')\n",
    "    print('\\nIndividual Reviews:')\n",
    "    for review in reviews:\n",
    "        print(f\"\\nAuthor: {review['author']}\\nDate: {review['date']}\\nTitle: {review['title']}\\nBody: {review['body']}\\nVerified Purchase: {review['verified_purchase']}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jordan 3 Retro Mid White Cement Reimagined\n",
      "Average Rating: 5.0\n",
      "Total Ratings: 50 average ratings\n",
      "\n",
      "Individual Reviews:\n",
      "\n",
      "Author: by derekfirefighter\n",
      "Date: March 26, 2023\n",
      "Title: Got to have them in the closet\n",
      "Body: Good pair\n",
      "Verified Purchase: March 26, 2023\n",
      "\n",
      "\n",
      "Author: by charlottenorthcak\n",
      "Date: March 26, 2023\n",
      "Title: a classic that's easy to rock\n",
      "Body: shoes are fire and much needed! so glad to have these shoes in hand\n",
      "Verified Purchase: March 26, 2023\n",
      "\n",
      "\n",
      "Author: by anbre5370\n",
      "Date: March 26, 2023\n",
      "Title: Possibility of sneaker off the year\n",
      "Body: These are amazing. Very nice sneakers. This could definitely be sneaker off the year.\n",
      "Verified Purchase: March 26, 2023\n",
      "\n",
      "\n",
      "Author: by rumble20hz\n",
      "Date: June 14, 2023\n",
      "Title: 1 of my fav sneaks.\n",
      "Body: These sneaks are fiya!!!\n",
      "Verified Purchase: June 14, 2023\n",
      "\n",
      "\n",
      "Author: by malaka105\n",
      "Date: January 06, 2024\n",
      "Title: Classic sneaker - great deal\n",
      "Body: Great show.  Looked close to new.  Very happy with them\n",
      "Verified Purchase: January 06, 2024\n",
      "\n",
      "\n",
      "Author: by nungaray711\n",
      "Date: April 04, 2023\n",
      "Title: quality wasn't great by Nike!\n",
      "Body: Nike did a lousy job on the cement parts\n",
      "Verified Purchase: April 04, 2023\n",
      "\n",
      "\n",
      "Author: by rcjbbp13\n",
      "Date: March 29, 2023\n",
      "Title: Jordan 3 WC are sweet!\n",
      "Body: Classic silhouette with reimagined colors and aged look. So excited to have these. They look great and feel like decent quality! Definitely recommend if you like Jordan 3s.\n",
      "Verified Purchase: March 29, 2023\n",
      "\n",
      "\n",
      "Author: by armrah-56\n",
      "Date: April 11, 2023\n",
      "Title: Everything was great, 10/10\n",
      "Body: Its great! I love the shoe, box came undamaged, no marks on the shoe or anything.\n",
      "Verified Purchase: April 11, 2023\n",
      "\n",
      "\n",
      "Author: by eric2800\n",
      "Date: March 17, 2023\n",
      "Title: Remake of a classic!\n",
      "Body: Beautiful shoe ! Not the most comfortable, but a great shoe!\n",
      "Verified Purchase: March 17, 2023\n",
      "\n",
      "\n",
      "Author: by jyusi23\n",
      "Date: July 01, 2023\n",
      "Title: Jordan 4 White Cements\n",
      "Body: Awesome shoes!  My wife loves them!  Thanks!\n",
      "Verified Purchase: July 01, 2023\n",
      "\n"
     ]
    }
   ],
   "source": [
    "get_amazon_reviews(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting autoscraper\n",
      "  Downloading autoscraper-1.1.14-py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: requests in e:\\zain\\env\\lib\\site-packages (from autoscraper) (2.31.0)\n",
      "Collecting bs4 (from autoscraper)\n",
      "  Downloading bs4-0.0.1.tar.gz (1.1 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting lxml (from autoscraper)\n",
      "  Downloading lxml-5.1.0-cp39-cp39-win_amd64.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: beautifulsoup4 in e:\\zain\\env\\lib\\site-packages (from bs4->autoscraper) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in e:\\zain\\env\\lib\\site-packages (from requests->autoscraper) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in e:\\zain\\env\\lib\\site-packages (from requests->autoscraper) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in e:\\zain\\env\\lib\\site-packages (from requests->autoscraper) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in e:\\zain\\env\\lib\\site-packages (from requests->autoscraper) (2023.11.17)\n",
      "Requirement already satisfied: soupsieve>1.2 in e:\\zain\\env\\lib\\site-packages (from beautifulsoup4->bs4->autoscraper) (2.5)\n",
      "Downloading lxml-5.1.0-cp39-cp39-win_amd64.whl (3.9 MB)\n",
      "   ---------------------------------------- 0.0/3.9 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/3.9 MB 640.0 kB/s eta 0:00:07\n",
      "   ---------------------------------------- 0.0/3.9 MB 393.8 kB/s eta 0:00:10\n",
      "    --------------------------------------- 0.1/3.9 MB 655.4 kB/s eta 0:00:06\n",
      "   - -------------------------------------- 0.2/3.9 MB 762.6 kB/s eta 0:00:05\n",
      "   -- ------------------------------------- 0.2/3.9 MB 958.6 kB/s eta 0:00:04\n",
      "   --- ------------------------------------ 0.3/3.9 MB 1.0 MB/s eta 0:00:04\n",
      "   --- ------------------------------------ 0.4/3.9 MB 1.0 MB/s eta 0:00:04\n",
      "   ---- ----------------------------------- 0.4/3.9 MB 1.0 MB/s eta 0:00:04\n",
      "   ----- ---------------------------------- 0.6/3.9 MB 1.2 MB/s eta 0:00:03\n",
      "   ------ --------------------------------- 0.6/3.9 MB 1.4 MB/s eta 0:00:03\n",
      "   ------- -------------------------------- 0.7/3.9 MB 1.3 MB/s eta 0:00:03\n",
      "   -------- ------------------------------- 0.9/3.9 MB 1.5 MB/s eta 0:00:03\n",
      "   --------- ------------------------------ 0.9/3.9 MB 1.5 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 0.9/3.9 MB 1.5 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 0.9/3.9 MB 1.5 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 0.9/3.9 MB 1.5 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 0.9/3.9 MB 1.5 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 0.9/3.9 MB 1.5 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 0.9/3.9 MB 1.5 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 2.0/3.9 MB 2.1 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 2.3/3.9 MB 2.3 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 2.3/3.9 MB 2.3 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 2.3/3.9 MB 2.3 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 2.4/3.9 MB 2.1 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 3.1/3.9 MB 2.6 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 3.1/3.9 MB 2.6 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 3.3/3.9 MB 2.5 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 3.3/3.9 MB 2.5 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 3.4/3.9 MB 2.5 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 3.4/3.9 MB 2.5 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 3.4/3.9 MB 2.5 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 3.5/3.9 MB 2.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  3.9/3.9 MB 2.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  3.9/3.9 MB 2.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  3.9/3.9 MB 2.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 3.9/3.9 MB 2.3 MB/s eta 0:00:00\n",
      "Building wheels for collected packages: bs4\n",
      "  Building wheel for bs4 (setup.py): started\n",
      "  Building wheel for bs4 (setup.py): finished with status 'done'\n",
      "  Created wheel for bs4: filename=bs4-0.0.1-py3-none-any.whl size=1262 sha256=8e35ec7a391284aee6d7289eb65792e52e303f42e1488cccec7aa4268bf7dff6\n",
      "  Stored in directory: c:\\users\\huzaifa tahir\\appdata\\local\\pip\\cache\\wheels\\73\\2b\\cb\\099980278a0c9a3e57ff1a89875ec07bfa0b6fcbebb9a8cad3\n",
      "Successfully built bs4\n",
      "Installing collected packages: lxml, bs4, autoscraper\n",
      "Successfully installed autoscraper-1.1.14 bs4-0.0.1 lxml-5.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install autoscraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "FeatureNotFound",
     "evalue": "Couldn't find a tree builder with the features you requested: lxml. Do you need to install a parser library?",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFeatureNotFound\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m WantedList\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://www.amazon.com/AmazonBasics-Pound-Neoprene-Dumbbells-Weights/dp/B01LR5S6HK/?_encoding=UTF8&pd_rd_w=jX876&content-id=amzn1.sym.64be5821-f651-4b0b-8dd3-4f9b884f10e5&pf_rd_p=64be5821-f651-4b0b-8dd3-4f9b884f10e5&pf_rd_r=WQ1CA8YTG0VXZPBAXPPD&pd_rd_wg=jz7z3&pd_rd_r=bbc1b88d-65eb-4bf5-93ba-25759a3674a4&ref_=pd_gw_crs_zg_bs_3375251&th=1\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m      6\u001b[0m Scraper \u001b[38;5;241m=\u001b[39m AutoScraper()\n\u001b[1;32m----> 7\u001b[0m ScrapedData \u001b[38;5;241m=\u001b[39m \u001b[43mScraper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl_to_scrape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwanted_list\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mWantedList\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m (ScrapedData)\n",
      "File \u001b[1;32me:\\zain\\env\\lib\\site-packages\\autoscraper\\auto_scraper.py:227\u001b[0m, in \u001b[0;36mAutoScraper.build\u001b[1;34m(self, url, wanted_list, wanted_dict, html, request_args, update, text_fuzz_ratio)\u001b[0m\n\u001b[0;32m    178\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbuild\u001b[39m(\n\u001b[0;32m    179\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    180\u001b[0m     url\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    186\u001b[0m     text_fuzz_ratio\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m,\n\u001b[0;32m    187\u001b[0m ):\n\u001b[0;32m    188\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    189\u001b[0m \u001b[38;5;124;03m    Automatically constructs a set of rules to scrape the specified target[s] from a web page.\u001b[39;00m\n\u001b[0;32m    190\u001b[0m \u001b[38;5;124;03m        The rules are represented as stack_list.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    224\u001b[0m \u001b[38;5;124;03m    List of similar results\u001b[39;00m\n\u001b[0;32m    225\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 227\u001b[0m     soup \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_soup\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhtml\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhtml\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    229\u001b[0m     result_list \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    231\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m update \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n",
      "File \u001b[1;32me:\\zain\\env\\lib\\site-packages\\autoscraper\\auto_scraper.py:122\u001b[0m, in \u001b[0;36mAutoScraper._get_soup\u001b[1;34m(cls, url, html, request_args)\u001b[0m\n\u001b[0;32m    119\u001b[0m html \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_fetch_html(url, request_args)\n\u001b[0;32m    120\u001b[0m html \u001b[38;5;241m=\u001b[39m normalize(unescape(html))\n\u001b[1;32m--> 122\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mBeautifulSoup\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhtml\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlxml\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32me:\\zain\\env\\lib\\site-packages\\bs4\\__init__.py:250\u001b[0m, in \u001b[0;36mBeautifulSoup.__init__\u001b[1;34m(self, markup, features, builder, parse_only, from_encoding, exclude_encodings, element_classes, **kwargs)\u001b[0m\n\u001b[0;32m    248\u001b[0m     builder_class \u001b[38;5;241m=\u001b[39m builder_registry\u001b[38;5;241m.\u001b[39mlookup(\u001b[38;5;241m*\u001b[39mfeatures)\n\u001b[0;32m    249\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m builder_class \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 250\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m FeatureNotFound(\n\u001b[0;32m    251\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCouldn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt find a tree builder with the features you \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    252\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequested: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m. Do you need to install a parser library?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    253\u001b[0m             \u001b[38;5;241m%\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(features))\n\u001b[0;32m    255\u001b[0m \u001b[38;5;66;03m# At this point either we have a TreeBuilder instance in\u001b[39;00m\n\u001b[0;32m    256\u001b[0m \u001b[38;5;66;03m# builder, or we have a builder_class that we can instantiate\u001b[39;00m\n\u001b[0;32m    257\u001b[0m \u001b[38;5;66;03m# with the remaining **kwargs.\u001b[39;00m\n\u001b[0;32m    258\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m builder \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mFeatureNotFound\u001b[0m: Couldn't find a tree builder with the features you requested: lxml. Do you need to install a parser library?"
     ]
    }
   ],
   "source": [
    "from autoscraper import AutoScraper\n",
    " \n",
    "url_to_scrape=\"https://www.amazon.com/\"\n",
    "WantedList=[\"https://www.amazon.com/AmazonBasics-Pound-Neoprene-Dumbbells-Weights/dp/B01LR5S6HK/?_encoding=UTF8&pd_rd_w=jX876&content-id=amzn1.sym.64be5821-f651-4b0b-8dd3-4f9b884f10e5&pf_rd_p=64be5821-f651-4b0b-8dd3-4f9b884f10e5&pf_rd_r=WQ1CA8YTG0VXZPBAXPPD&pd_rd_wg=jz7z3&pd_rd_r=bbc1b88d-65eb-4bf5-93ba-25759a3674a4&ref_=pd_gw_crs_zg_bs_3375251&th=1\"]\n",
    " \n",
    "Scraper = AutoScraper()\n",
    "ScrapedData = Scraper.build(url_to_scrape, wanted_list=WantedList)\n",
    "print (ScrapedData)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
